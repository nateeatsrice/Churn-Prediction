{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOMxZUsH8yTt",
        "outputId": "d4a3370c-c368-47e1-c5eb-4fac13c964dd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/ML\\ Projects/Churn-Prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQljjzckeaZW",
        "outputId": "14bc8401-f8ca-4651-8f75-489452c4cc52"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML Projects/Churn-Prediction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s9lpXTatZd_R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mLPeZsFhZd_U"
      },
      "outputs": [],
      "source": [
        "#data wrangling and format standardization\n",
        "df = pd.read_csv('./Telco-Customer-Churn.csv')\n",
        "\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df['TotalCharges'] = df['TotalCharges'].fillna(0)\n",
        "\n",
        "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
        "\n",
        "string_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
        "\n",
        "for col in string_columns:\n",
        "    df[col] = df[col].str.lower().str.replace(' ', '_')\n",
        "\n",
        "df.churn = (df.churn == 'yes').astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UQXdCLHMZd_V"
      },
      "outputs": [],
      "source": [
        "#split full training and test set\n",
        "df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
        "\n",
        "df_train_full = df_train_full.reset_index(drop=True)\n",
        "df_test = df_test.reset_index(drop=True)\n",
        "# will use cross validation later so no need to create training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8DSuuEwRZd_W"
      },
      "outputs": [],
      "source": [
        "categorical = ['gender', 'seniorcitizen', 'partner', 'dependents',\n",
        "               'phoneservice', 'multiplelines', 'internetservice',\n",
        "               'onlinesecurity', 'onlinebackup', 'deviceprotection',\n",
        "               'techsupport', 'streamingtv', 'streamingmovies',\n",
        "               'contract', 'paperlessbilling', 'paymentmethod']\n",
        "numerical = ['tenure', 'monthlycharges', 'totalcharges']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tB520TYEZd_W"
      },
      "outputs": [],
      "source": [
        "def train(df, y, C):\n",
        "    # Dict vectorizer inputs a dictionary\n",
        "    cat = df[categorical + numerical].to_dict(orient='records')\n",
        "\n",
        "    dv = DictVectorizer(sparse=False)\n",
        "    dv.fit(cat)\n",
        "\n",
        "    X = dv.transform(cat)\n",
        "\n",
        "    model = LogisticRegression(solver='liblinear', C=C)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    return dv, model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(df, dv, model):\n",
        "    cat = df[categorical + numerical].to_dict(orient='records')\n",
        "\n",
        "    X = dv.transform(cat)\n",
        "\n",
        "    y_pred = model.predict_proba(X)[:, 1]\n",
        "\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "yu0NZwFSer6Z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using KFold Validation to see best model in using training set tested on validation set\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "\n",
        "# the C parameter is the inverse of the regularization strength\n",
        "# small value of C (e.g., 0.01 or 0.1) means a large regularization strength,\n",
        "# leading to a simpler model that is less prone to overfitting\n",
        "for C in [0.001, 0.01, 0.1, 0.5, 1, 10, 50]:\n",
        "    # aucs will be averaged to get the average auc per model\n",
        "    aucs = []\n",
        "\n",
        "    for train_idx, val_idx in kfold.split(df_train_full):\n",
        "        df_train = df_train_full.iloc[train_idx]\n",
        "        df_val = df_train_full.iloc[val_idx]\n",
        "\n",
        "        y_train = df_train.churn.values\n",
        "        y_val = df_val.churn.values\n",
        "\n",
        "        dv, model = train(df_train, y_train, C=C)\n",
        "        y_pred = predict(df_val, dv, model)\n",
        "\n",
        "        auc = roc_auc_score(y_val, y_pred)\n",
        "        aucs.append(auc)\n",
        "\n",
        "    print('C=%s, auc = %0.3f ± %0.3f' % (C, np.mean(aucs), np.std(aucs)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBieVIVmp4yS",
        "outputId": "c6e64fa8-d03f-4513-ce8d-7d85eda42faa"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=0.001, auc = 0.826 ± 0.016\n",
            "C=0.01, auc = 0.840 ± 0.012\n",
            "C=0.1, auc = 0.842 ± 0.012\n",
            "C=0.5, auc = 0.842 ± 0.012\n",
            "C=1, auc = 0.842 ± 0.012\n",
            "C=10, auc = 0.842 ± 0.012\n",
            "C=50, auc = 0.842 ± 0.012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "feYW7Tb-Zd_X"
      },
      "outputs": [],
      "source": [
        "# seeing that the best model was with C= 0.1 we now train on full training set (training+val) and compare with test\n",
        "y_train = df_train_full.churn.values\n",
        "y_test = df_test.churn.values\n",
        "C = 0.1\n",
        "# the model and dv below are ultimitly the file we want to export\n",
        "dv, model = train(df_train_full, y_train, C=C)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predict(df_test, dv, model)\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "print('auc = %.3f' % auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pM-ZhUAxkep",
        "outputId": "8003b3c4-43dd-4bdd-c1e6-2adcf86647a8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc = 0.858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set threshold to 0.5\n",
        "cm = confusion_matrix(y_test, y_pred >= 0.5)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZwzkGJ3t3la",
        "outputId": "a7bdf48e-1171-4c8d-a515-fa1db16337d5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[940 121]\n",
            " [144 204]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ZJAnzjHOZd_Y"
      },
      "outputs": [],
      "source": [
        "# model inference\n",
        "customer = {\n",
        "    'customerid': '8879-zkjof',\n",
        "    'gender': 'female',\n",
        "    'seniorcitizen': 0,\n",
        "    'partner': 'no',\n",
        "    'dependents': 'no',\n",
        "    'tenure': 41,\n",
        "    'phoneservice': 'yes',\n",
        "    'multiplelines': 'no',\n",
        "    'internetservice': 'dsl',\n",
        "    'onlinesecurity': 'yes',\n",
        "    'onlinebackup': 'no',\n",
        "    'deviceprotection': 'yes',\n",
        "    'techsupport': 'yes',\n",
        "    'streamingtv': 'yes',\n",
        "    'streamingmovies': 'yes',\n",
        "    'contract': 'one_year',\n",
        "    'paperlessbilling': 'yes',\n",
        "    'paymentmethod': 'bank_transfer_(automatic)',\n",
        "    'monthlycharges': 79.85,\n",
        "    'totalcharges': 3320.75\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXHnjmydZd_Z",
        "outputId": "fd804985-6ba1-4f76-f0c3-c3370a50e092"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.062085023937430026)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "#inference on the single example above\n",
        "df = pd.DataFrame([customer])\n",
        "y_pred = predict(df, dv, model)\n",
        "y_pred[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Sfr6XBwUZd_Z"
      },
      "outputs": [],
      "source": [
        "# make a function which automates the cell above\n",
        "def predict_single(customer, dv, model):\n",
        "    X = dv.transform([customer])\n",
        "    y_pred = model.predict_proba(X)[:, 1]\n",
        "    return y_pred[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRtzTGAnZd_a",
        "outputId": "24bf6a0e-7da2-48b4-e2fb-a618c5da7491"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.062085023937430026)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# not likely to churn\n",
        "predict_single(customer, dv, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "WwmbuodAZd_a"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_file = f\"logregmodel_C={C}.bin\"\n",
        "output_file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9h9dtRZuzCe-",
        "outputId": "eef86850-7cd0-44d7-85fd-db59739352d0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'logregmodel_C=0.1.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 'wb' means we want to write to the file and it is going to be binary\n",
        "# f_out = open(output_file,'wb')\n",
        "# # pickle.dump saves the output, since dv is required we save with model as tuple\n",
        "# pickle.dump((dv,model),f_out)\n",
        "# #make sure to close, will use \"with\" function which does this automatically\n",
        "# f_out.close()"
      ],
      "metadata": {
        "id": "EuaBENFIy1fa"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# same as code above, './churn-model.bin' names the file and directory\n",
        "with open('./churn-model.bin', 'wb') as f_out:\n",
        "    pickle.dump((dv, model), f_out)"
      ],
      "metadata": {
        "id": "iRe-INf1y03W"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "scrolled": false,
        "id": "g_ukvoPgZd_a"
      },
      "outputs": [],
      "source": [
        "# import requests\n",
        "# url = 'http://localhost:9696/predict'\n",
        "# response = requests.post(url, json=customer)\n",
        "# result = response.json()\n",
        "# result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__UX_8aqZd_b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}